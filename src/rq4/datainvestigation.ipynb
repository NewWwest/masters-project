{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'D:\\Projects\\aaa')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils.utils import get_files_in_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = r'D:\\Projects\\aaa\\results\\rq4_results\\features.csv'\n",
    "npm = r'D:\\Projects\\aaa\\results\\rq4_results\\features_npm.csv'\n",
    "pypi = r'D:\\Projects\\aaa\\results\\rq4_results\\features_pypi.csv'\n",
    "mvn = r'D:\\Projects\\aaa\\results\\rq4_results\\features_mvn.csv'\n",
    "\n",
    "df = pd.read_csv(npm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33336, 161)\n",
      "561\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print((df['label_security_related']==True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize time_to_next_merge where nan is a valid value\n",
    "max_merge = df['time_to_next_merge'].max() * 10\n",
    "df.loc[df['time_to_next_merge'].isna(),'time_to_next_merge'] = max_merge\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df.dropna(axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = {col:0 for col in df}\n",
    "\n",
    "for col in df:\n",
    "    nan_counts = df[col].isna().sum()\n",
    "    asd[col] = nan_counts/df.shape[0]\n",
    "\n",
    "asd = {k: v for k,v in sorted(asd.items(), key=lambda kv: -kv[1])}\n",
    "# print(asd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33336, 157)\n",
      "(170, 157)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.violinplot(X['attack_in_file_content'])\n",
    "print(X.shape)\n",
    "print(X[X['attack_in_file_content'] > 0.8].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\aaa\\src\\rq4\\datainvestigation.ipynb Cell 8\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/aaa/src/rq4/datainvestigation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_sec \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mlabel_security_related\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/aaa/src/rq4/datainvestigation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/aaa/src/rq4/datainvestigation.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     dfx \u001b[39m=\u001b[39m df[df[col]\u001b[39m<\u001b[39m\u001b[39m10\u001b[39m] \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/aaa/src/rq4/datainvestigation.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     dfx_sec \u001b[39m=\u001b[39m df_sec[df_sec[col]\u001b[39m<\u001b[39m\u001b[39m10\u001b[39m] \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/aaa/src/rq4/datainvestigation.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(col)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3458\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3459\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3460\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mand\u001b[39;00m isna(key) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# added_lines_ratio_avg\n",
    "# dmm_unit_size\n",
    "\n",
    "# columns = X.columns\n",
    "columns = ['']\n",
    "\n",
    "df_sec = df[df['label_security_related'] == True]\n",
    "for col in columns:\n",
    "    dfx = df[df[col]<10] \n",
    "    dfx_sec = df_sec[df_sec[col]<10] \n",
    "    print(col)\n",
    "    violin_parts = plt.violinplot(dfx[col])\n",
    "    violin_parts['bodies'][0].set_facecolor('blue')\n",
    "    violin_parts = plt.violinplot(dfx_sec[col])\n",
    "    violin_parts['bodies'][0].set_facecolor('red')\n",
    "    plt.ylim(0, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33336, 161)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt   \n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, tzinfo\n",
    "import pytz\n",
    "#ether/etherpad-lite\n",
    "#openpgpjs/openpgpjs\n",
    "\n",
    "\n",
    "#added_lines_count_avg - good\n",
    "#authent_in_title - bad\n",
    "# to investigate: max_method_complexity_avg\n",
    "\n",
    "repo = None #'ether/etherpad-lite'\n",
    "if repo != None:\n",
    "    dfx = df[df['label_repo_full_name']==repo]\n",
    "else:\n",
    "    dfx=df\n",
    "\n",
    "print(dfx.shape)\n",
    "df_sec = dfx[dfx['label_security_related'] == True]\n",
    "x_axis = dfx['label_commit_date'].apply(parser.parse)\n",
    "x_axis = [(x.replace(tzinfo=pytz.utc)-datetime.utcnow().replace(tzinfo=pytz.utc)).total_seconds() / 3600 for x in x_axis]\n",
    "x_axis_sec = df_sec['label_commit_date'].apply(parser.parse)\n",
    "x_axis_sec = [(x.replace(tzinfo=pytz.utc)-datetime.utcnow().replace(tzinfo=pytz.utc)).total_seconds() / 3600 for x in x_axis_sec]\n",
    "\n",
    "columns = X\n",
    "columns = ['authent_in_title']\n",
    "\n",
    "for col in columns:\n",
    "    # plt.title(col)\n",
    "    plt.scatter(x_axis, dfx[col], color='b', marker='o')\n",
    "    plt.xlim(-45000,10)\n",
    "    plt.scatter(x_axis_sec, df_sec[col], color='r', marker='x')\n",
    "    plt.ylabel('Commit contains the substring \"authent\" in the title')\n",
    "    plt.xlabel('Time')\n",
    "    plt.show()\n",
    "    print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_lines_count_max   changed_lines_count_max   0.6961159301722354\n",
      "added_lines_ratio_avg   added_lines_ratio_max   0.7689495507801307\n",
      "added_lines_ratio_avg   removed_lines_ratio_avg   -0.9809811106720578\n",
      "added_lines_ratio_avg   removed_lines_ratio_max   -0.7019301666874392\n",
      "added_lines_ratio_max   removed_lines_ratio_avg   -0.7470861084459047\n",
      "authored_by_bot   committed_by_bot   0.8124391069477949\n",
      "avg_method_complexity_avg   avg_method_nloc_avg   0.6390260726068608\n",
      "avg_method_complexity_avg   avg_method_token_count_avg   0.5917264244058608\n",
      "avg_method_complexity_avg   max_method_complexity_avg   0.7413519860974221\n",
      "avg_method_complexity_avg   max_method_complexity_max   0.5776634633729855\n",
      "avg_method_nloc_avg   avg_method_nloc_max   0.735621679547693\n",
      "avg_method_nloc_avg   avg_method_token_count_avg   0.6764765022023822\n",
      "avg_method_nloc_avg   max_method_nloc_avg   0.6708249192051\n",
      "avg_method_nloc_max   avg_method_token_count_max   0.5642267607170814\n",
      "avg_method_nloc_max   max_method_nloc_avg   0.5816391491884549\n",
      "avg_method_nloc_max   max_method_nloc_max   0.6308281052728152\n",
      "avg_method_parameter_count_avg   avg_method_parameter_count_max   0.7713742824087141\n",
      "avg_method_parameter_count_avg   max_method_parameter_count_avg   0.777108906662265\n",
      "avg_method_parameter_count_avg   max_method_parameter_count_max   0.5936650511760687\n",
      "avg_method_parameter_count_max   max_method_parameter_count_avg   0.5831685166494498\n",
      "avg_method_parameter_count_max   max_method_parameter_count_max   0.7153462146504368\n",
      "avg_method_token_count_avg   avg_method_token_count_max   0.687251538959274\n",
      "avg_method_token_count_avg   max_method_token_count_avg   0.6504613356487418\n",
      "avg_method_token_count_max   max_method_token_count_avg   0.5884581634583925\n",
      "avg_method_token_count_max   max_method_token_count_max   0.6252118612287545\n",
      "changed_lines_count_max   modified_lines_count_max   0.5398925586579235\n",
      "changed_lines_count_max   removed_lines_count_max   0.8368834680042544\n",
      "changed_methods_count_avg   file_changed_method_count_avg   0.9999999999997057\n",
      "changed_methods_count_avg   file_changed_method_count_max   0.7362748579178644\n",
      "changes_to_file_in_next_50_commits_max   changes_to_file_in_prev_50_commits_avg   0.7200525951686838\n",
      "changes_to_file_in_next_50_commits_max   changes_to_file_in_prev_50_commits_max   0.875899569762154\n",
      "changes_to_file_in_prev_50_commits_avg   changes_to_file_in_prev_50_commits_max   0.8334610147264516\n",
      "commits_next_30_days   commits_next_7_days   0.6915895772417329\n",
      "commits_next_7_days   commits_prev_7_days   0.7121046265219901\n",
      "corrupt_in_file_content   corrupt_in_patch   0.5571575217529026\n",
      "dmm_unit_interfacing   dmm_unit_size   0.6125898121697219\n",
      "file_changed_method_count_avg   file_changed_method_count_max   0.7362748576437131\n",
      "file_changed_method_count_max   total_methods_count_max   0.5532852603367698\n",
      "file_complexity_avg   file_complexity_max   0.9172749318640697\n",
      "file_complexity_max   file_token_count_max   0.5337576005230559\n",
      "file_complexity_max   total_methods_count_max   0.5433589601461186\n",
      "file_nloc_avg   file_nloc_max   0.7479791451980847\n",
      "file_nloc_avg   file_token_count_avg   0.5199111243929485\n",
      "file_nloc_max   total_methods_count_max   0.5600994905769977\n",
      "file_size_max   file_token_count_avg   0.6121502388064495\n",
      "file_size_max   file_token_count_max   0.6957482901528022\n",
      "file_size_max   total_methods_count_max   0.7075389538927286\n",
      "file_token_count_avg   file_token_count_max   0.84483156162629\n",
      "file_token_count_avg   max_method_token_count_avg   0.6172115775447304\n",
      "file_token_count_avg   max_method_token_count_max   0.5560660668561918\n",
      "file_token_count_avg   total_methods_count_max   0.8359915211000848\n",
      "file_token_count_max   max_method_token_count_avg   0.5390221695016911\n",
      "file_token_count_max   max_method_token_count_max   0.6360853353442072\n",
      "file_token_count_max   total_methods_count_max   0.9462254182483958\n",
      "is_add   is_modify   -0.8088017051322361\n",
      "max_method_complexity_avg   max_method_complexity_max   0.7678791043849239\n",
      "max_method_complexity_avg   max_method_token_count_avg   0.6153857410818062\n",
      "max_method_complexity_max   max_method_token_count_avg   0.5159758607831902\n",
      "max_method_complexity_max   max_method_token_count_max   0.6322283948636649\n",
      "max_method_nloc_avg   max_method_nloc_max   0.7763874354414141\n",
      "max_method_nloc_avg   max_method_token_count_avg   0.5211924028564072\n",
      "max_method_parameter_count_avg   max_method_parameter_count_max   0.7875672771683752\n",
      "max_method_token_count_avg   max_method_token_count_max   0.8184188405589924\n",
      "max_method_token_count_max   total_methods_count_max   0.5873582660723212\n",
      "methods_with_attack_count_avg   methods_with_attack_count_max   0.8006170328245733\n",
      "methods_with_authent_count_avg   methods_with_authent_count_max   0.5148829823959403\n",
      "methods_with_certificat_count_avg   methods_with_certificat_count_max   0.6340851107819926\n",
      "methods_with_corrupt_count_avg   methods_with_corrupt_count_max   1.0000000000000002\n",
      "methods_with_corrupt_count_avg   methods_with_leak_count_max   0.5184581201101971\n",
      "methods_with_corrupt_count_max   methods_with_leak_count_max   0.5184581201101929\n",
      "methods_with_deadlock_count_avg   methods_with_deadlock_count_max   0.9999999999999978\n",
      "methods_with_exploit_count_avg   methods_with_exploit_count_max   1.0000000000000009\n",
      "methods_with_leak_count_avg   methods_with_leak_count_max   0.7364108087409404\n",
      "methods_with_secur_count_avg   methods_with_secur_count_max   0.5730261723924355\n",
      "methods_with_sensit_count_avg   methods_with_sensit_count_max   0.5001176913745835\n",
      "modified_lines_ratio_avg   modified_lines_ratio_max   0.7590763984944494\n",
      "removed_lines_ratio_avg   removed_lines_ratio_max   0.7211240840827483\n"
     ]
    }
   ],
   "source": [
    "broken_features = [\n",
    "    'commits_to_next_merge',\n",
    "    'commits_since_last_merge',\n",
    "    'commits_to_next_merge'   \n",
    "    'commits_since_last_merge'\n",
    "]\n",
    "\n",
    "highly_correlated_features = [\n",
    "    'dmm_unit_complexity',\n",
    "    'secur_in_title',\n",
    "    'vulnerab_in_title',\n",
    "    'exploit_in_title',\n",
    "    'certificat_in_title',\n",
    "    'authent_in_title',\n",
    "    'leak_in_title',\n",
    "    'sensit_in_title',\n",
    "    'crash_in_title',\n",
    "    'attack_in_title',\n",
    "    'deadlock_in_title',\n",
    "    'segfault_in_title',\n",
    "    'malicious_in_title',\n",
    "    'corrupt_in_title',\n",
    "    'test_in_filename',\n",
    "    'removed_lines_count_avg',\n",
    "    'added_lines_count_avg',\n",
    "    'changed_lines_count_avg',\n",
    "    'modified_lines_count_avg',\n",
    "    'file_size_avg',\n",
    "    'changed_methods_count_max',\n",
    "    'total_methods_count_avg',\n",
    "    'max_method_token_count_avg'\n",
    "    'avg_method_complexity_avg',\n",
    "    'avg_method_complexity_max',\n",
    "    'avg_method_parameter_count_max'\n",
    "\n",
    "    'changes_to_file_in_prev_50_commits_avg',\n",
    "    'changes_to_file_in_next_50_commits_avg'\n",
    "]\n",
    "\n",
    "\n",
    "df_new = df\n",
    "df_new = df_new[df_new.columns.difference(broken_features)]\n",
    "df_new = df_new[df_new.columns.difference(highly_correlated_features)]\n",
    "\n",
    "X_new = df_new[df_new.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
    "y = df_new['label_security_related']\n",
    "\n",
    "correlation_matrix = X_new.corr()\n",
    "corr = correlation_matrix.values\n",
    "column_names = correlation_matrix.columns\n",
    "\n",
    "for i in range(len(column_names)):\n",
    "    for j in range(i+1, len(column_names)):\n",
    "        if abs(corr[i,j])> 0.5:\n",
    "            print(column_names[i], ' ', column_names[j], ' ', corr[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33336, 131)\n",
      "(1122, 131)\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 1/5; 1/3] END ..............n_estimators=50;, score=0.600 total time=   0.0s\n",
      "[CV 2/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 2/5; 1/3] END ..............n_estimators=50;, score=0.523 total time=   0.0s\n",
      "[CV 3/5; 1/3] START n_estimators=50.............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 3 is smaller than n_iter=15. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/3] END ..............n_estimators=50;, score=0.603 total time=   0.0s\n",
      "[CV 4/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 4/5; 1/3] END ..............n_estimators=50;, score=0.612 total time=   0.0s\n",
      "[CV 5/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 5/5; 1/3] END ..............n_estimators=50;, score=0.695 total time=   0.0s\n",
      "[CV 1/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 1/5; 2/3] END ..............n_estimators=75;, score=0.598 total time=   0.0s\n",
      "[CV 2/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 2/5; 2/3] END ..............n_estimators=75;, score=0.600 total time=   0.0s\n",
      "[CV 3/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 3/5; 2/3] END ..............n_estimators=75;, score=0.607 total time=   0.0s\n",
      "[CV 4/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 4/5; 2/3] END ..............n_estimators=75;, score=0.623 total time=   0.0s\n",
      "[CV 5/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 5/5; 2/3] END ..............n_estimators=75;, score=0.706 total time=   0.0s\n",
      "[CV 1/5; 3/3] START n_estimators=100............................................\n",
      "[CV 1/5; 3/3] END .............n_estimators=100;, score=0.569 total time=   0.1s\n",
      "[CV 2/5; 3/3] START n_estimators=100............................................\n",
      "[CV 2/5; 3/3] END .............n_estimators=100;, score=0.627 total time=   0.1s\n",
      "[CV 3/5; 3/3] START n_estimators=100............................................\n",
      "[CV 3/5; 3/3] END .............n_estimators=100;, score=0.639 total time=   0.1s\n",
      "[CV 4/5; 3/3] START n_estimators=100............................................\n",
      "[CV 4/5; 3/3] END .............n_estimators=100;, score=0.609 total time=   0.1s\n",
      "[CV 5/5; 3/3] START n_estimators=100............................................\n",
      "[CV 5/5; 3/3] END .............n_estimators=100;, score=0.708 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 3 is smaller than n_iter=15. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 1/5; 1/3] END ..............n_estimators=50;, score=0.592 total time=   0.0s\n",
      "[CV 2/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 2/5; 1/3] END ..............n_estimators=50;, score=0.708 total time=   0.0s\n",
      "[CV 3/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 3/5; 1/3] END ..............n_estimators=50;, score=0.651 total time=   0.0s\n",
      "[CV 4/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 4/5; 1/3] END ..............n_estimators=50;, score=0.623 total time=   0.0s\n",
      "[CV 5/5; 1/3] START n_estimators=50.............................................\n",
      "[CV 5/5; 1/3] END ..............n_estimators=50;, score=0.684 total time=   0.0s\n",
      "[CV 1/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 1/5; 2/3] END ..............n_estimators=75;, score=0.565 total time=   0.0s\n",
      "[CV 2/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 2/5; 2/3] END ..............n_estimators=75;, score=0.693 total time=   0.0s\n",
      "[CV 3/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 3/5; 2/3] END ..............n_estimators=75;, score=0.636 total time=   0.0s\n",
      "[CV 4/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 4/5; 2/3] END ..............n_estimators=75;, score=0.640 total time=   0.0s\n",
      "[CV 5/5; 2/3] START n_estimators=75.............................................\n",
      "[CV 5/5; 2/3] END ..............n_estimators=75;, score=0.684 total time=   0.0s\n",
      "[CV 1/5; 3/3] START n_estimators=100............................................\n",
      "[CV 1/5; 3/3] END .............n_estimators=100;, score=0.560 total time=   0.1s\n",
      "[CV 2/5; 3/3] START n_estimators=100............................................\n",
      "[CV 2/5; 3/3] END .............n_estimators=100;, score=0.711 total time=   0.1s\n",
      "[CV 3/5; 3/3] START n_estimators=100............................................\n",
      "[CV 3/5; 3/3] END .............n_estimators=100;, score=0.630 total time=   0.1s\n",
      "[CV 4/5; 3/3] START n_estimators=100............................................\n",
      "[CV 4/5; 3/3] END .............n_estimators=100;, score=0.605 total time=   0.1s\n",
      "[CV 5/5; 3/3] START n_estimators=100............................................\n",
      "[CV 5/5; 3/3] END .............n_estimators=100;, score=0.696 total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_rus, y_rus = rus.fit_resample(X_new, y)\n",
    "print(X_new.shape)\n",
    "print(X_rus.shape)\n",
    "\n",
    "VERBOSE_LVL = 10\n",
    "n_iter = 15\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': list([50, 75, 100])\n",
    "    }\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model_random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter,\n",
    "    scoring = 'f1',\n",
    "    refit=True,\n",
    "    cv=5,\n",
    "    verbose=VERBOSE_LVL)\n",
    "\n",
    "result = model_random_search.fit(X_rus, y_rus)\n",
    "selector = RFECV(result.best_estimator_, prefit=True)\n",
    "\n",
    "X_new2 = selector.transform(X_new)\n",
    "rus = RandomUnderSampler()\n",
    "X_rus, y_rus = rus.fit_resample(X_new2, y)\n",
    "result = model_random_search.fit(X_rus, y_rus)\n",
    "\n",
    "# result = model_random_search.fit(X_new_new, y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
