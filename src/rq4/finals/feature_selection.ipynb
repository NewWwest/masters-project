{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'D:\\Projects\\aaa')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed() \n",
    "\n",
    "from src.utils.utils import get_files_in_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allx = r'D:\\Projects\\aaa\\results\\rq4_results\\features.csv'\n",
    "npm = r'D:\\Projects\\aaa\\results\\rq4_results\\features_npm.csv'\n",
    "pypi = r'D:\\Projects\\aaa\\results\\rq4_results\\features_pypi.csv'\n",
    "mvn = r'D:\\Projects\\aaa\\results\\rq4_results\\features_mvn.csv'\n",
    "\n",
    "df_all = pd.read_csv(npm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize time_to_next_merge where nan is a valid value\n",
    "max_merge = df_all['time_to_next_merge'].max() * 10\n",
    "df_all.loc[df_all['time_to_next_merge'].isna(),'time_to_next_merge'] = max_merge\n",
    "\n",
    "df_all.fillna(0, inplace=True)\n",
    "df_all.fillna(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.shape[0])\n",
    "print((df_all['label_security_related']==True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_byrepo = df_all.groupby('label_repo_full_name')\n",
    "repos = df_all['label_repo_full_name'].unique()\n",
    "train_repos = random.sample(list(repos), int(0.9*len(repos)))\n",
    "df = df_all[df_all.apply(lambda x: x['label_repo_full_name'] in train_repos, axis=1)]\n",
    "eval_df = df_all[df_all.apply(lambda x: x['label_repo_full_name'] not in train_repos, axis=1)]\n",
    "\n",
    "print(df.shape, (df['label_security_related']==True).sum())\n",
    "print(eval_df.shape, (eval_df['label_security_related']==True).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_ratio = {col:0 for col in df}\n",
    "\n",
    "# for col in df:\n",
    "#     nan_counts = df[col].isna().sum()\n",
    "#     nan_ratio[col] = nan_counts/df.shape[0]\n",
    "\n",
    "# nan_ratio = {k: v for k,v in sorted(nan_ratio.items(), key=lambda kv: -kv[1])}\n",
    "# for k,v in nan_ratio.item():\n",
    "#     if v > 0.1:\n",
    "#         print(nan_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_features = [\n",
    "    'commits_to_next_merge',\n",
    "    'commits_since_last_merge',\n",
    "    'commits_to_next_merge',\n",
    "    'commits_since_last_merge',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_variance_features = [\n",
    "    'methods_with_attack_count_avg',\n",
    "    'methods_with_corrupt_count_avg',\n",
    "    'methods_with_corrupt_count_max',\n",
    "    'methods_with_crash_count_avg',\n",
    "    'methods_with_crash_count_max',\n",
    "    'methods_with_deadlock_count_avg',\n",
    "    'methods_with_deadlock_count_max',\n",
    "    'methods_with_exploit_count_avg',\n",
    "    'methods_with_exploit_count_max',\n",
    "    'methods_with_leak_count_avg',\n",
    "    'methods_with_malicious_count_avg',\n",
    "    'methods_with_malicious_count_max',\n",
    "    'methods_with_segfault_count_avg',\n",
    "    'methods_with_segfault_count_max',\n",
    "    'methods_with_sensit_count_avg',\n",
    "    'methods_with_vulnerab_count_avg',\n",
    "    'methods_with_vulnerab_count_max',\n",
    "    'segfault_in_file_content',\n",
    "    'segfault_in_message',\n",
    "    'segfault_in_patch',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated_features = [\n",
    "    'added_lines_count_avg',\n",
    "    'added_lines_ratio_avg',\n",
    "\n",
    "    'secur_in_title',\n",
    "    'vulnerab_in_title',\n",
    "    'exploit_in_title',\n",
    "    'certificat_in_title',\n",
    "    'authent_in_title',\n",
    "    'leak_in_title',\n",
    "    'sensit_in_title',\n",
    "    'crash_in_title',\n",
    "    'attack_in_title',\n",
    "    'deadlock_in_title',\n",
    "    'segfault_in_title',\n",
    "    'malicious_in_title',\n",
    "    'corrupt_in_title',\n",
    "\n",
    "    'committed_by_bot',\n",
    "\n",
    "    'avg_method_complexity_avg',\n",
    "    'file_complexity_max',\n",
    "    'file_token_count_max',\n",
    "    'file_changed_method_count_max',\n",
    "    'file_nloc_max',\n",
    "    'max_method_token_count_avg',\n",
    "    'total_methods_count_max',\n",
    "\n",
    "    \n",
    "    'changes_to_file_in_prev_50_commits_avg',\n",
    "    'changes_to_file_in_next_50_commits_avg',\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_selected = df\n",
    "df_selected = df_selected[df_selected.columns.difference(broken_features)]\n",
    "df_selected = df_selected[df_selected.columns.difference(no_variance_features)]\n",
    "df_selected = df_selected[df_selected.columns.difference(highly_correlated_features)]\n",
    "\n",
    "X = df_selected[df_selected.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
    "y = df_selected['label_security_related']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.001)\n",
    "sel.fit(X)\n",
    "sup = sel.get_support()\n",
    "i = -1\n",
    "for x in X:\n",
    "       i+=1\n",
    "       if not sup[i]:\n",
    "              print(f'reject \\'{x}\\',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X.corr()\n",
    "corr = correlation_matrix.values\n",
    "column_names = correlation_matrix.columns\n",
    "\n",
    "for i in range(len(column_names)):\n",
    "    for j in range(i+1, len(column_names)):\n",
    "        if abs(corr[i,j])> 0.75:\n",
    "            print('reject', column_names[i], ' ', column_names[j], ' ', corr[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# manual rebalancing\n",
    "oversample_ratio = 2\n",
    "undersample_ratio = 2\n",
    "\n",
    "x_positive = X.where(y).dropna()\n",
    "x_negative = X.where(y==False).dropna()\n",
    "\n",
    "x_positive = pd.concat([x_positive for i in range(oversample_ratio)])\n",
    "x_negative = x_negative.sample(len(x_positive)*undersample_ratio)\n",
    "\n",
    "X_resampled = pd.concat([x_negative, x_positive])\n",
    "y_resampled = np.array([False]*len(x_negative) + [True]*len(x_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_positive.shape, x_negative.shape, X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical rebalancing\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "# sampler = SMOTE()\n",
    "# X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "scaler = RobustScaler().fit(X_resampled)\n",
    "X_resampled = scaler.transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "VERBOSE_LVL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train selector & RF\n",
    "    \n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 100,\n",
    "    random_state=42)\n",
    "\n",
    "selector = RFECV(model, \n",
    "    step=1, \n",
    "    cv=5,\n",
    "    min_features_to_select=40,\n",
    "    scoring = 'f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=VERBOSE_LVL)\n",
    "\n",
    "selector.fit(X_resampled, y_resampled)\n",
    "\n",
    "print('max f1:', max(selector.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_keys(['mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "# print(selector.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colums = list(X.columns)\n",
    "\n",
    "print('Selected features')\n",
    "for i in range(len(selector.support_)):\n",
    "    if selector.support_[i]:\n",
    "        print(colums[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_eval_selected = eval_df\n",
    "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(broken_features)]\n",
    "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(no_variance_features)]\n",
    "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(highly_correlated_features)]\n",
    "\n",
    "eval_X = df_eval_selected[df_eval_selected.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
    "eval_y = df_eval_selected['label_security_related']\n",
    "\n",
    "\n",
    "eval_x_positive = eval_X.where(eval_y).dropna()\n",
    "eval_x_negative = eval_X.where(eval_y==False).dropna()\n",
    "print(eval_x_positive.shape, eval_x_negative.shape)\n",
    "\n",
    "eval_x_negative_sampled =  eval_x_negative.sample(len(eval_x_positive)*undersample_ratio)\n",
    "\n",
    "eval_X_balanced = pd.concat([eval_x_negative_sampled, eval_x_positive])\n",
    "eval_y_balanced = np.array([False]*len(eval_x_negative_sampled) + [True]*len(eval_x_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval RF selector\n",
    "\n",
    "eval_scaled = scaler.transform(eval_X)\n",
    "eval_selected_scaled = selector.transform(eval_scaled)\n",
    "X_resampled_selected = selector.transform(X_resampled)\n",
    "eval_X_balanced_selected = selector.transform(eval_X_balanced)\n",
    "\n",
    "train_preds = selector.predict(X_resampled)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('RF train', recall, precision)\n",
    "\n",
    "eval_balanced_y_pred = selector.predict(eval_X_balanced)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('RF test', recall, precision)\n",
    "\n",
    "eval_y_pred = selector.predict(eval_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "\n",
    "print('RF eval', recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(\n",
    "    kernel ='linear',\n",
    "    cache_size=1000,\n",
    "    random_state=42)\n",
    "\n",
    "SVC_model.fit(X_resampled_selected, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model_2 = SVC(\n",
    "    kernel ='sigmoid',\n",
    "    random_state=42)\n",
    "\n",
    "SVC_model_2.fit(X_resampled_selected, y_resampled)\n",
    "\n",
    "train_preds = SVC_model_2.predict(X_resampled_selected)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('SVC2 train', recall, precision)\n",
    "\n",
    "eval_balanced_y_pred = SVC_model_2.predict(eval_X_balanced_selected)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('SVC2 test', recall, precision)\n",
    "\n",
    "eval_y_pred = SVC_model_2.predict(eval_selected_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "print('SVC2 eval', recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_preds = SVC_model.predict(X_resampled_selected)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('SVC train', recall, precision)\n",
    "\n",
    "eval_balanced_y_pred = SVC_model.predict(eval_X_balanced_selected)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('SVC test', recall, precision)\n",
    "\n",
    "eval_y_pred = SVC_model.predict(eval_selected_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "print('SVC test', recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(\n",
    "    penalty ='l2',\n",
    "    max_iter = 20000,\n",
    "    random_state=42)\n",
    "\n",
    "LR_model.fit(X_resampled_selected, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = LR_model.predict(X_resampled_selected)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('LR train', recall, precision)\n",
    "\n",
    "\n",
    "eval_balanced_y_pred = LR_model.predict(eval_X_balanced_selected)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('LR test', recall, precision)\n",
    "\n",
    "eval_y_pred = LR_model.predict(eval_selected_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "print('LR eval', recall, precision)\n",
    "\n",
    "# eval_y_pred = LR_model.predict(eval_selected_scaled)\n",
    "# recall = recall_score(eval_y, eval_y_pred)\n",
    "# precision = precision_score(eval_y, eval_y_pred)\n",
    "# print('LR', recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(eval_selected_scaled)) #3308\n",
    "# (3308, 161) 45 => \n",
    "\n",
    "# 3076 commits ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_y_pred4 = selector.predict(eval_scaled)\n",
    "eval_y_pred = [False]*len(eval_y_pred4)\n",
    "\n",
    "for x in range(len(eval_y_pred4)):\n",
    "    if eval_y_pred4[x]:\n",
    "        eval_y_pred[x]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = [False]*len(eval_y)\n",
    "eval_y2 = eval_y.reset_index()\n",
    "for x in range(len(eval_y2)):\n",
    "    if eval_y_pred4[x] and eval_y2.iloc[x]['label_security_related']:\n",
    "        x_true[x]=True\n",
    "    \n",
    "true_positives = sum(1  for x in x_true if x)\n",
    "al_positives = (eval_df['label_security_related']==True).sum()\n",
    "print(true_positives/al_positives) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ix = 0\n",
    "shas = []\n",
    "for i, x in eval_df.iterrows():\n",
    "    shas.append({\n",
    "        'label_sha':x['label_sha'],\n",
    "        'label_repo_full_name':x['label_repo_full_name'],\n",
    "        'classification_pred': eval_y_pred[ix]\n",
    "    })\n",
    "\n",
    "    ix += 1\n",
    "\n",
    "with open('classificated_commits.json', 'w') as f:\n",
    "    json.dump(shas, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(LR_model, 'LR_model_all.joblib') \n",
    "dump(SVC_model_2, 'SVC_model_2_all.joblib') \n",
    "dump(SVC_model, 'SVC_model_all.joblib') \n",
    "dump(LR_model, 'LR_model_all.joblib') \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
