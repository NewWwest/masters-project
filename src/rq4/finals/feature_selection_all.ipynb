{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'D:\\Projects\\aaa')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed() \n",
    "\n",
    "from src.utils.utils import get_files_in_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allx = r'D:\\Projects\\aaa\\results\\rq4_results\\features.csv'\n",
    "npm = r'D:\\Projects\\aaa\\results\\rq4_results\\features_npm.csv'\n",
    "pypi = r'D:\\Projects\\aaa\\results\\rq4_results\\features_pypi.csv'\n",
    "mvn = r'D:\\Projects\\aaa\\results\\rq4_results\\features_mvn.csv'\n",
    "\n",
    "df_all = pd.read_csv(allx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize time_to_next_merge where nan is a valid value\n",
    "max_merge = df_all['time_to_next_merge'].max() * 10\n",
    "df_all.loc[df_all['time_to_next_merge'].isna(),'time_to_next_merge'] = max_merge\n",
    "\n",
    "df_all.fillna(0, inplace=True)\n",
    "df_all.fillna(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425891\n",
      "7986\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape[0])\n",
    "print((df_all['label_security_related']==True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381654, 161) 7118\n",
      "(44237, 161) 868\n"
     ]
    }
   ],
   "source": [
    "_byrepo = df_all.groupby('label_repo_full_name')\n",
    "repos = df_all['label_repo_full_name'].unique()\n",
    "train_repos = random.sample(list(repos), int(0.9*len(repos)))\n",
    "df = df_all[df_all.apply(lambda x: x['label_repo_full_name'] in train_repos, axis=1)]\n",
    "eval_df = df_all[df_all.apply(lambda x: x['label_repo_full_name'] not in train_repos, axis=1)]\n",
    "\n",
    "print(df.shape, (df['label_security_related']==True).sum())\n",
    "print(eval_df.shape, (eval_df['label_security_related']==True).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_ratio = {col:0 for col in df}\n",
    "\n",
    "# for col in df:\n",
    "#     nan_counts = df[col].isna().sum()\n",
    "#     nan_ratio[col] = nan_counts/df.shape[0]\n",
    "\n",
    "# nan_ratio = {k: v for k,v in sorted(nan_ratio.items(), key=lambda kv: -kv[1])}\n",
    "# for k,v in nan_ratio.item():\n",
    "#     if v > 0.1:\n",
    "#         print(nan_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_features = [\n",
    "    'commits_to_next_merge',\n",
    "    'commits_since_last_merge',\n",
    "    'commits_to_next_merge',\n",
    "    'commits_since_last_merge',\n",
    "    'file_changed_method_count_avg',\n",
    "    'file_changed_method_count_max',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_variance_features = [\n",
    "    'has_npm_like_code',\n",
    "    'has_pypi_like_code',\n",
    "    'methods_with_attack_count_avg',\n",
    "    'methods_with_corrupt_count_avg',\n",
    "    'methods_with_crash_count_avg',\n",
    "    'methods_with_deadlock_count_avg',\n",
    "    'methods_with_deadlock_count_max',\n",
    "    'methods_with_malicious_count_avg',\n",
    "    'methods_with_malicious_count_max',\n",
    "    'methods_with_segfault_count_avg',\n",
    "    'methods_with_segfault_count_max',\n",
    "    'methods_with_sensit_count_avg',\n",
    "    'methods_with_vulnerab_count_avg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated_features = [\n",
    "    'attack_in_title',\n",
    "    'corrupt_in_title',\n",
    "    'deadlock_in_title',\n",
    "    'malicious_in_title',\n",
    "    'segfault_in_title',\n",
    "    'sensit_in_title',\n",
    "    'secur_in_title',\n",
    "    # 'vulnerab_in_title',\n",
    "    'exploit_in_title',\n",
    "    'certificat_in_title',\n",
    "    # 'authent_in_title',\n",
    "    'leak_in_title',\n",
    "    # 'crash_in_title',\n",
    "\n",
    "    'avg_method_nloc_max',\n",
    "    'avg_method_complexity_max',\n",
    "    'avg_method_complexity_avg',\n",
    "    'avg_method_nloc_avg',\n",
    "    'avg_method_token_count_avg',\n",
    "    'avg_method_parameter_count_avg',\n",
    "    'avg_method_parameter_count_max',\n",
    "    'methods_with_exploit_count_avg',\n",
    "    'max_method_parameter_count_avg',\n",
    "    \n",
    "    \n",
    "    'file_complexity_max',\n",
    "    'file_nloc_max',\n",
    "\n",
    "    'added_lines_ratio_avg',\n",
    "    'added_lines_count_max',\n",
    "    'added_lines_count_avg',\n",
    "\n",
    "    'changes_to_file_in_next_50_commits_avg',\n",
    "    'changes_to_file_in_prev_50_commits_avg',\n",
    "    \n",
    "    'test_in_filename',\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_selected = df\n",
    "df_selected = df_selected[df_selected.columns.difference(broken_features)]\n",
    "df_selected = df_selected[df_selected.columns.difference(no_variance_features)]\n",
    "df_selected = df_selected[df_selected.columns.difference(highly_correlated_features)]\n",
    "\n",
    "X = df_selected[df_selected.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
    "y = df_selected['label_security_related']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reject 'deadlock_in_patch',\n",
      "reject 'malicious_in_message',\n",
      "reject 'segfault_in_message',\n",
      "reject 'segfault_in_patch',\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.001)\n",
    "sel.fit(X)\n",
    "sup = sel.get_support()\n",
    "i = -1\n",
    "for x in X:\n",
    "       i+=1\n",
    "       if not sup[i]:\n",
    "              print(f'reject \\'{x}\\',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['segfault_in_message', 'segfault_in_patch', 'malicious_in_message', 'deadlock_in_patch']\n",
    "\n",
    "# df_sec = df[df['label_security_related'] == True]\n",
    "# for col in columns:\n",
    "#     dfx = df[df[col]<10] \n",
    "#     dfx_sec = df_sec[df_sec[col]<10] \n",
    "#     print(col)\n",
    "#     violin_parts = plt.violinplot(dfx[col])\n",
    "#     violin_parts['bodies'][0].set_facecolor('blue')\n",
    "#     violin_parts = plt.violinplot(dfx_sec[col])\n",
    "#     violin_parts['bodies'][0].set_facecolor('red')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reject added_lines_ratio_max   removed_lines_ratio_avg   -0.8350279698398552\n",
      "reject avg_method_token_count_max   max_method_token_count_max   0.9225748723132765\n",
      "reject changed_lines_count_avg   removed_lines_count_avg   0.864161865435166\n",
      "reject changes_to_file_in_next_50_commits_max   changes_to_file_in_prev_50_commits_max   0.8910599975909784\n",
      "reject commits_next_30_days   commits_next_7_days   0.7520832864460798\n",
      "reject dmm_unit_complexity   dmm_unit_size   0.8402009290021557\n",
      "reject file_nloc_avg   file_token_count_avg   0.8171397364093848\n",
      "reject file_token_count_avg   file_token_count_max   0.8068504214976031\n",
      "reject is_add   is_modify   -0.8533059472257891\n",
      "reject max_method_nloc_avg   max_method_token_count_avg   0.8533927079744009\n",
      "reject max_method_nloc_max   max_method_token_count_max   0.7802640057875394\n",
      "reject modified_lines_ratio_avg   modified_lines_ratio_max   0.8621459946131086\n",
      "reject removed_lines_ratio_avg   removed_lines_ratio_max   0.8368331099712139\n",
      "reject total_methods_count_avg   total_methods_count_max   0.7963766737279044\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = X.corr()\n",
    "corr = correlation_matrix.values\n",
    "column_names = correlation_matrix.columns\n",
    "\n",
    "for i in range(len(column_names)):\n",
    "    for j in range(i+1, len(column_names)):\n",
    "        if abs(corr[i,j])> 0.75:\n",
    "            print('reject', column_names[i], ' ', column_names[j], ' ', corr[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected\n"
     ]
    }
   ],
   "source": [
    "print('Features selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# manual rebalancing\n",
    "oversample_ratio = 2\n",
    "undersample_ratio = 2\n",
    "\n",
    "x_positive = X.where(y).dropna()\n",
    "x_negative = X.where(y==False).dropna()\n",
    "\n",
    "x_positive = pd.concat([x_positive for i in range(oversample_ratio)])\n",
    "x_negative = x_negative.sample(len(x_positive)*undersample_ratio)\n",
    "\n",
    "X_resampled = pd.concat([x_negative, x_positive])\n",
    "y_resampled = np.array([False]*len(x_negative) + [True]*len(x_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "\n",
    "# # statistical rebalancing with SMOTE AID\n",
    "# oversample_ratio = 2\n",
    "# undersample_ratio = 1\n",
    "\n",
    "# sampler = SMOTE()\n",
    "\n",
    "# x_positive = X.where(y).dropna()\n",
    "# x_negative = X.where(y==False).dropna()\n",
    "\n",
    "# x_negative_temp = x_negative.sample(len(x_positive)*oversample_ratio)\n",
    "# X_resampled_temp = pd.concat([x_negative_temp, x_positive])\n",
    "# y_resampled_temp = np.array([False]*len(x_negative_temp) + [True]*len(x_positive))\n",
    "\n",
    "# X_resampled_temp, y_resampled_temp = sampler.fit_resample(X_resampled_temp, y_resampled_temp)\n",
    "\n",
    "# x_negative_temp2 = x_negative.sample(len(X_resampled_temp)*undersample_ratio)\n",
    "# X_resampled = np.concatenate([X_resampled_temp, x_negative_temp2])\n",
    "# y_resampled = np.concatenate([y_resampled_temp, [False]*(len(X_resampled_temp)*undersample_ratio)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14236, 113) (28472, 113) (42708, 113)\n"
     ]
    }
   ],
   "source": [
    "print(x_positive.shape, x_negative.shape, X_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler().fit(X_resampled)\n",
    "X_resampled = scaler.transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "VERBOSE_LVL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "max f1: 0.9573853611189452\n"
     ]
    }
   ],
   "source": [
    "# Train selector & RF\n",
    "    \n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 100,\n",
    "    random_state=42)\n",
    "\n",
    "selector = RFECV(model, \n",
    "    step=1, \n",
    "    cv=5,\n",
    "    min_features_to_select=40,\n",
    "    scoring = 'f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=VERBOSE_LVL)\n",
    "\n",
    "selector.fit(X_resampled, y_resampled)\n",
    "\n",
    "print('max f1:', max(selector.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_keys(['mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "# print(selector.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features\n",
      "added_lines_ratio_max\n",
      "attack_in_file_content\n",
      "attack_in_message\n",
      "attack_in_patch\n",
      "authent_in_file_content\n",
      "authent_in_message\n",
      "authent_in_patch\n",
      "authent_in_title\n",
      "author_in_top_100\n",
      "author_to_commiter_date_diff\n",
      "authored_by_bot\n",
      "avg_method_token_count_max\n",
      "certificat_in_file_content\n",
      "certificat_in_patch\n",
      "changed_files\n",
      "changed_lines_count_avg\n",
      "changed_lines_count_max\n",
      "changed_methods_count_avg\n",
      "changed_methods_count_max\n",
      "changes_to_file_in_next_50_commits_max\n",
      "changes_to_file_in_prev_50_commits_max\n",
      "commits_next_30_days\n",
      "commits_next_7_days\n",
      "commits_prev_7_days\n",
      "committed_by_bot\n",
      "corrupt_in_file_content\n",
      "corrupt_in_message\n",
      "corrupt_in_patch\n",
      "crash_in_file_content\n",
      "crash_in_message\n",
      "crash_in_patch\n",
      "crash_in_title\n",
      "deadlock_in_file_content\n",
      "dmm_unit_complexity\n",
      "dmm_unit_interfacing\n",
      "dmm_unit_size\n",
      "exploit_in_file_content\n",
      "exploit_in_message\n",
      "exploit_in_patch\n",
      "file_complexity_avg\n",
      "file_nloc_avg\n",
      "file_size_avg\n",
      "file_size_max\n",
      "file_token_count_avg\n",
      "file_token_count_max\n",
      "has_mvn_code\n",
      "has_mvn_like_code\n",
      "has_npm_code\n",
      "has_pypi_code\n",
      "is_add\n",
      "is_delete\n",
      "is_file_recently_added\n",
      "is_file_recently_removed\n",
      "is_modify\n",
      "leak_in_file_content\n",
      "leak_in_message\n",
      "leak_in_patch\n",
      "malicious_in_file_content\n",
      "malicious_in_message\n",
      "malicious_in_patch\n",
      "max_method_complexity_avg\n",
      "max_method_complexity_max\n",
      "max_method_nloc_avg\n",
      "max_method_nloc_max\n",
      "max_method_parameter_count_max\n",
      "max_method_token_count_avg\n",
      "max_method_token_count_max\n",
      "methods_with_secur_count_avg\n",
      "modified_lines_count_avg\n",
      "modified_lines_count_max\n",
      "modified_lines_ratio_avg\n",
      "modified_lines_ratio_max\n",
      "removed_lines_count_avg\n",
      "removed_lines_count_max\n",
      "removed_lines_ratio_avg\n",
      "removed_lines_ratio_max\n",
      "same_author_as_commiter\n",
      "secur_in_file_content\n",
      "secur_in_message\n",
      "secur_in_patch\n",
      "segfault_in_file_content\n",
      "segfault_in_message\n",
      "sensit_in_file_content\n",
      "sensit_in_patch\n",
      "test_in_path\n",
      "time_to_next_commit\n",
      "time_to_next_merge\n",
      "time_to_prev_commit\n",
      "total_methods_count_avg\n",
      "total_methods_count_max\n",
      "vulnerab_in_file_content\n",
      "vulnerab_in_message\n",
      "vulnerab_in_patch\n",
      "vulnerab_in_title\n"
     ]
    }
   ],
   "source": [
    "colums = list(X.columns)\n",
    "\n",
    "print('Selected features')\n",
    "for i in range(len(selector.support_)):\n",
    "    if selector.support_[i]:\n",
    "        print(colums[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 113) (43369, 113)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_eval_selected = eval_df\n",
    "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(broken_features)]\n",
    "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(no_variance_features)]\n",
    "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(highly_correlated_features)]\n",
    "\n",
    "eval_X = df_eval_selected[df_eval_selected.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
    "eval_y = df_eval_selected['label_security_related']\n",
    "\n",
    "\n",
    "eval_x_positive = eval_X.where(eval_y).dropna()\n",
    "eval_x_negative = eval_X.where(eval_y==False).dropna()\n",
    "print(eval_x_positive.shape, eval_x_negative.shape)\n",
    "\n",
    "eval_x_negative_sampled =  eval_x_negative.sample(len(eval_x_positive)*undersample_ratio)\n",
    "\n",
    "eval_X_balanced = pd.concat([eval_x_negative_sampled, eval_x_positive])\n",
    "eval_y_balanced = np.array([False]*len(eval_x_negative_sampled) + [True]*len(eval_x_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RFECV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train 1.0 0.9997893110471241\n",
      "RF test 0.10944700460829493 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RFECV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF eval 0.25 0.197992700729927\n"
     ]
    }
   ],
   "source": [
    "# eval RF selector\n",
    "\n",
    "eval_scaled = scaler.transform(eval_X)\n",
    "eval_selected_scaled = selector.transform(eval_scaled)\n",
    "X_resampled_selected = selector.transform(X_resampled)\n",
    "eval_X_balanced_selected = selector.transform(eval_X_balanced)\n",
    "\n",
    "train_preds = selector.predict(X_resampled)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('RF train', recall, precision)\n",
    "\n",
    "eval_balanced_y_pred = selector.predict(eval_X_balanced)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('RF test', recall, precision)\n",
    "\n",
    "eval_y_pred = selector.predict(eval_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "\n",
    "print('RF eval', recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(\n",
    "    kernel ='linear',\n",
    "    cache_size=1000,\n",
    "    random_state=42)\n",
    "\n",
    "SVC_model.fit(X_resampled_selected, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_preds = SVC_model.predict(X_resampled_selected)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('SVC train', recall, precision)\n",
    "\n",
    "eval_balanced_y_pred = SVC_model.predict(eval_X_balanced_selected)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('SVC test', recall, precision)\n",
    "\n",
    "eval_y_pred = SVC_model.predict(eval_selected_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "print('SVC test', recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model_2 = SVC(\n",
    "    kernel ='sigmoid',\n",
    "    random_state=42)\n",
    "\n",
    "SVC_model_2.fit(X_resampled_selected, y_resampled)\n",
    "\n",
    "train_preds = SVC_model_2.predict(X_resampled_selected)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('SVC2 train', recall, precision)\n",
    "\n",
    "eval_balanced_y_pred = SVC_model_2.predict(eval_X_balanced_selected)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('SVC2 test', recall, precision)\n",
    "\n",
    "eval_y_pred = SVC_model_2.predict(eval_selected_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "print('SVC2 eval', recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=20000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=20000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=20000, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model = LogisticRegression(\n",
    "    penalty ='l2',\n",
    "    max_iter = 20000,\n",
    "    random_state=42)\n",
    "\n",
    "LR_model.fit(X_resampled_selected, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR train 0.34490025288002246 0.724188790560472\n",
      "LR test 0.14400921658986174 0.3351206434316354\n",
      "LR eval 0.3076036866359447 0.12936046511627908\n"
     ]
    }
   ],
   "source": [
    "train_preds = LR_model.predict(X_resampled_selected)\n",
    "recall = recall_score(y_resampled, train_preds)\n",
    "precision = precision_score(y_resampled, train_preds)\n",
    "print('LR train', recall, precision)\n",
    "\n",
    "\n",
    "eval_balanced_y_pred = LR_model.predict(eval_X_balanced_selected)\n",
    "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
    "print('LR test', recall, precision)\n",
    "\n",
    "eval_y_pred = LR_model.predict(eval_selected_scaled)\n",
    "recall = recall_score(eval_y, eval_y_pred)\n",
    "precision = precision_score(eval_y, eval_y_pred)\n",
    "print('LR eval', recall, precision)\n",
    "\n",
    "# eval_y_pred = LR_model.predict(eval_selected_scaled)\n",
    "# recall = recall_score(eval_y, eval_y_pred)\n",
    "# precision = precision_score(eval_y, eval_y_pred)\n",
    "# print('LR', recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44237\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_selected_scaled)) #3308\n",
    "# (3308, 161) 45 => \n",
    "\n",
    "# 3076 commits ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_y_pred4 = LR_model.predict(eval_selected_scaled)\n",
    "eval_y_pred = [False]*len(eval_y_pred4)\n",
    "\n",
    "for x in range(len(eval_y_pred4)):\n",
    "    if eval_y_pred4[x]:\n",
    "        eval_y_pred[x]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3076036866359447\n"
     ]
    }
   ],
   "source": [
    "x_true = [False]*len(eval_y)\n",
    "eval_y2 = eval_y.reset_index()\n",
    "for x in range(len(eval_y2)):\n",
    "    if eval_y_pred4[x] and eval_y2.iloc[x]['label_security_related']:\n",
    "        x_true[x]=True\n",
    "    \n",
    "true_positives = sum(1  for x in x_true if x)\n",
    "al_positives = (eval_df['label_security_related']==True).sum()\n",
    "print(true_positives/al_positives) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ix = 0\n",
    "shas = []\n",
    "for i, x in eval_df.iterrows():\n",
    "    shas.append({\n",
    "        'label_sha':x['label_sha'],\n",
    "        'label_repo_full_name':x['label_repo_full_name'],\n",
    "        'classification_pred': eval_y_pred[ix]\n",
    "    })\n",
    "\n",
    "    ix += 1\n",
    "\n",
    "with open('classificated_commits.json', 'w') as f:\n",
    "    json.dump(shas, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_model_all.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(LR_model, 'LR_model_all.joblib') \n",
    "# dump(SVC_model_2, 'SVC_model_2_all.joblib') \n",
    "# dump(SVC_model, 'SVC_model_all.joblib') \n",
    "dump(LR_model, 'LR_model_all.joblib') \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
