{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dateutil.parser as parser\n",
    "from statistics import mean, median\n",
    "\n",
    "seconds_in_a_day = 24*3600\n",
    "with open(r'data\\revall_analysis.json', 'r') as f:\n",
    "    recall_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subset = recall_data\n",
    "npm_subset = {k:v for k,v in recall_data.items() if 'ecosystem' in v and 'npm' in v['ecosystem']}\n",
    "pypi_subset = {k:v for k,v in recall_data.items() if 'ecosystem' in v and 'pypi' in v['ecosystem']}\n",
    "mvn_subset = {k:v for k,v in recall_data.items() if 'ecosystem' in v and 'maven' in v['ecosystem']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All entities - first reference to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delay(delays_data_subset, date_key, label):\n",
    "    for x in delays_data_subset:\n",
    "        if 'creation_date' in delays_data_subset[x] and delays_data_subset[x]['creation_date'] and date_key in delays_data_subset[x] and delays_data_subset[x][date_key]:\n",
    "            creation_date = parser.parse(delays_data_subset[x]['creation_date'])\n",
    "            ref_date = min([parser.parse(y[1])for y in delays_data_subset[x][date_key]])\n",
    "            diff = creation_date-ref_date\n",
    "            delays = diff.total_seconds()/seconds_in_a_day\n",
    "            delays_data_subset[x][f'{date_key}_diff'] = delays\n",
    "        \n",
    "    ids_all = len([1 for x in delays_data_subset if 'creation_date' in delays_data_subset[x] and delays_data_subset[x]['creation_date']])\n",
    "    ids_with_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x]])\n",
    "    ids_with_positive_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x] and delays_data_subset[x][f'{date_key}_diff']>0])\n",
    "    ids_with_week_old_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x] and delays_data_subset[x][f'{date_key}_diff']>7])\n",
    "\n",
    "    diffs = [delays_data_subset[x][f'{date_key}_diff'] for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x]]\n",
    "\n",
    "    print(label)\n",
    "    print(date_key)\n",
    "    print('count', ids_with_diffs)\n",
    "    print('median', median(diffs))\n",
    "    print('recall at 0', ids_with_positive_diffs/ids_all)\n",
    "    print('recall at 7', ids_with_week_old_diffs/ids_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delays_ref(delays_data_subset, date_key, label):\n",
    "    for x in delays_data_subset:\n",
    "        if 'creation_date' in delays_data_subset[x] and delays_data_subset[x]['creation_date'] and date_key in delays_data_subset[x] and delays_data_subset[x][date_key]:\n",
    "            creation_date = parser.parse(delays_data_subset[x]['creation_date'])\n",
    "            ref_date = min([parser.parse(y[1])for y in delays_data_subset[x][date_key]])\n",
    "            diff = creation_date-ref_date\n",
    "            delays = diff.total_seconds()/seconds_in_a_day\n",
    "            delays_data_subset[x][f'{date_key}_diff'] = delays\n",
    "        \n",
    "    ids_with_refs = len([1 for x in delays_data_subset if ('first_issue' in delays_data_subset[x] and delays_data_subset[x]['first_issue']) or ('first_commit' in delays_data_subset[x] and delays_data_subset[x]['first_commit'])])\n",
    "    ids_with_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x]])\n",
    "    ids_with_positive_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x] and delays_data_subset[x][f'{date_key}_diff']>0])\n",
    "    ids_with_week_old_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x] and delays_data_subset[x][f'{date_key}_diff']>7])\n",
    "\n",
    "    diffs = [delays_data_subset[x][f'{date_key}_diff'] for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x]]\n",
    "\n",
    "    print(label)\n",
    "    print(date_key)\n",
    "    print('count', ids_with_diffs)\n",
    "    print('median', median(diffs))\n",
    "    print('recall at 0', ids_with_positive_diffs/ids_with_refs)\n",
    "    print('recall at 7', ids_with_week_old_diffs/ids_with_refs)\n",
    "    print('recall at 30', ids_with_week_old_diffs/ids_with_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delays_issues(delays_data_subset, date_key, label):\n",
    "    for x in delays_data_subset:\n",
    "        if 'creation_date' in delays_data_subset[x] and delays_data_subset[x]['creation_date'] and date_key in delays_data_subset[x] and delays_data_subset[x][date_key]:\n",
    "            creation_date = parser.parse(delays_data_subset[x]['creation_date'])\n",
    "            ref_date = min([parser.parse(y[1])for y in delays_data_subset[x][date_key]])\n",
    "            diff = creation_date-ref_date\n",
    "            delays = diff.total_seconds()/seconds_in_a_day\n",
    "            delays_data_subset[x][f'{date_key}_diff'] = delays\n",
    "        \n",
    "    ids_with_issues = len([1 for x in delays_data_subset if ('first_issue' in delays_data_subset[x] and delays_data_subset[x]['first_issue'])])\n",
    "    ids_with_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x]])\n",
    "    ids_with_positive_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x] and delays_data_subset[x][f'{date_key}_diff']>0])\n",
    "    ids_with_week_old_diffs = len([1 for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x] and delays_data_subset[x][f'{date_key}_diff']>7])\n",
    "\n",
    "    diffs = [delays_data_subset[x][f'{date_key}_diff'] for x in delays_data_subset if f'{date_key}_diff' in delays_data_subset[x]]\n",
    "\n",
    "    print(label)\n",
    "    print(date_key)\n",
    "    print('count', ids_with_diffs)\n",
    "    print('median', median(diffs))\n",
    "    print('recall at 0', ids_with_positive_diffs/ids_with_issues)\n",
    "    print('recall at 7', ids_with_week_old_diffs/ids_with_issues)\n",
    "    print('recall at 30', ids_with_week_old_diffs/ids_with_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_ref(delays_data_subset, label):\n",
    "    calculate_delay(delays_data_subset, 'first_ref', label)\n",
    "\n",
    "first_ref(recall_data, 'All')\n",
    "first_ref(npm_subset, 'npm')\n",
    "first_ref(pypi_subset, 'pypi')\n",
    "first_ref(mvn_subset, 'mvn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_issue(delays_data_subset, label):\n",
    "    calculate_delay(delays_data_subset, 'first_issue', label)\n",
    "\n",
    "first_issue(recall_data, 'All')\n",
    "first_issue(npm_subset, 'npm')\n",
    "first_issue(pypi_subset, 'pypi')\n",
    "first_issue(mvn_subset, 'mvn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_commit(delays_data_subset, label):\n",
    "    calculate_delay(delays_data_subset, 'first_commit', label)\n",
    "\n",
    "first_commit(recall_data, 'All')\n",
    "first_commit(npm_subset, 'npm')\n",
    "first_commit(pypi_subset, 'pypi')\n",
    "first_commit(mvn_subset, 'mvn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_sec_phrase(delays_data_subset, label):\n",
    "    calculate_delays_ref(delays_data_subset, 'first_sec_phrase', label)\n",
    "\n",
    "first_sec_phrase(recall_data, 'All')\n",
    "first_sec_phrase(npm_subset, 'npm')\n",
    "first_sec_phrase(pypi_subset, 'pypi')\n",
    "first_sec_phrase(mvn_subset, 'mvn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_sec_label(delays_data_subset, label):\n",
    "    calculate_delays_issues(delays_data_subset, 'first_sec_label', label)\n",
    "\n",
    "first_sec_label(recall_data, 'All')\n",
    "first_sec_label(npm_subset, 'npm')\n",
    "first_sec_label(pypi_subset, 'pypi')\n",
    "first_sec_label(mvn_subset, 'mvn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
