{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cBFlduQai3pW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "random.seed(42)\n",
        "np.random.seed(42) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dILPdch8i9CD",
        "outputId": "cc8b1f99-7f0e-44a0-9175-a409fb54a9cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\AnJ\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3251: DtypeWarning: Columns (160) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "allx = r'D:\\Projects\\aaa\\results\\rq4_results\\new_features.csv'\n",
        "\n",
        "df_all = pd.read_csv(allx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kxe9Fq3Ri96C"
      },
      "outputs": [],
      "source": [
        "# Sanitize time_to_next_merge where nan is a valid value\n",
        "max_merge = df_all['time_to_next_merge'].max() * 10\n",
        "df_all.loc[df_all['time_to_next_merge'].isna(),'time_to_next_merge'] = max_merge\n",
        "\n",
        "df_all.fillna(0, axis=0, inplace=True)\n",
        "df_all.fillna(0, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s2SZTj0i-_i",
        "outputId": "0e01c73e-06ca-4e18-dd36-43495965d905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "425891\n",
            "7986\n"
          ]
        }
      ],
      "source": [
        "print(df_all.shape[0])\n",
        "print((df_all['label_security_related']==True).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ-hT0Tl6JSU",
        "outputId": "b5d74566-3f4a-4d2a-fce6-bfede97ba68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "378980 7069\n",
            "46911 917\n"
          ]
        }
      ],
      "source": [
        "_byrepo = df_all.groupby('label_repo_full_name')\n",
        "repos = df_all['label_repo_full_name'].unique()\n",
        "train_repos = random.sample(list(repos), int(0.9*len(repos)))\n",
        "df = df_all[df_all.apply(lambda x: x['label_repo_full_name'] in train_repos, axis=1)]\n",
        "eval_df = df_all[df_all.apply(lambda x: x['label_repo_full_name'] not in train_repos, axis=1)]\n",
        "\n",
        "print(df.shape[0], (df['label_security_related']==True).sum())\n",
        "print(eval_df.shape[0], (eval_df['label_security_related']==True).sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFi-0kbJAazD"
      },
      "source": [
        "# Feature Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BJBX3gDDjBKB"
      },
      "outputs": [],
      "source": [
        "broken_features = [\n",
        "    'file_changed_method_count_avg',\n",
        "    'file_changed_method_count_max',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M245Sg72jByx"
      },
      "outputs": [],
      "source": [
        "no_variance_features = [\n",
        "    'methods_with_attack_count_avg',\n",
        "    'methods_with_corrupt_count_avg',\n",
        "    'methods_with_crash_count_avg',\n",
        "    'methods_with_deadlock_count_avg',\n",
        "    'methods_with_deadlock_count_max',\n",
        "    'methods_with_exploit_count_avg',\n",
        "    'methods_with_exploit_count_max',\n",
        "    'methods_with_segfault_count_avg',\n",
        "    'methods_with_segfault_count_max',\n",
        "    'methods_with_sensit_count_avg',\n",
        "    'methods_with_vulnerab_count_avg',\n",
        "\n",
        "    'has_npm_like_code', \n",
        "    'has_pypi_like_code',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QpKYquMUjC1B"
      },
      "outputs": [],
      "source": [
        "highly_correlated_features = [\n",
        "  'attack_in_title',\n",
        "  'corrupt_in_title',\n",
        "  'deadlock_in_title',\n",
        "  'malicious_in_title',\n",
        "  'segfault_in_title',\n",
        "  'sensit_in_title',\n",
        "  'secur_in_title',\n",
        "  # 'vulnerab_in_title',\n",
        "  'exploit_in_title',\n",
        "  'certificat_in_title',\n",
        "  # 'authent_in_title',\n",
        "  'leak_in_title',\n",
        "  # 'crash_in_title',\n",
        "\n",
        "  'added_lines_count_avg',\n",
        "  'added_lines_count_max',\n",
        "  'added_lines_ratio_avg',\n",
        "  'added_lines_ratio_max',\n",
        "  'avg_method_complexity_max',\n",
        "  'max_method_complexity_avg',\n",
        "  'max_method_nloc_avg',\n",
        "  'avg_method_nloc_max',\n",
        "  'avg_method_parameter_count_max',\n",
        "  'max_method_parameter_count_avg',\n",
        "  'file_complexity_max',\n",
        "  'max_method_token_count_avg',\n",
        "  'avg_method_token_count_max',\n",
        "  'test_in_filename',\n",
        "  'modified_lines_ratio_avg',\n",
        "  'removed_lines_ratio_avg',\n",
        "  'avg_method_nloc_avg',\n",
        "  'max_method_nloc_max',\n",
        "  'file_nloc_avg',\n",
        "  'file_nloc_max',\n",
        "  'changes_to_file_in_next_50_commits_max',\n",
        "  'changes_to_file_in_prev_50_commits_max',\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F3B25Q96jD8R"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_selected = df\n",
        "df_selected = df_selected[df_selected.columns.difference(broken_features)]\n",
        "df_selected = df_selected[df_selected.columns.difference(no_variance_features)]\n",
        "df_selected = df_selected[df_selected.columns.difference(highly_correlated_features)]\n",
        "\n",
        "X = df_selected[df_selected.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
        "y = df_selected['label_security_related']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3dfQNO0jEzB",
        "outputId": "9d9dc7c9-52fc-4cff-cf86-c57152e6c78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reject 'deadlock_in_patch',\n",
            "reject 'exploit_in_message',\n",
            "reject 'exploit_in_patch',\n",
            "reject 'malicious_in_message',\n",
            "reject 'malicious_in_patch',\n",
            "reject 'methods_with_malicious_count_avg',\n",
            "reject 'methods_with_malicious_count_max',\n",
            "reject 'segfault_in_message',\n",
            "reject 'segfault_in_patch',\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "sel = VarianceThreshold(threshold=0.001)\n",
        "sel.fit(X)\n",
        "sup = sel.get_support()\n",
        "i = -1\n",
        "for x in X:\n",
        "       i+=1\n",
        "       if not sup[i]:\n",
        "              print(f'reject \\'{x}\\',')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hfw3A9d0jGIB"
      },
      "outputs": [],
      "source": [
        "columns = [\n",
        "]\n",
        "# columns = ['methods_with_segfault_count_max']\n",
        "\n",
        "df_sec = df[df['label_security_related'] == True]\n",
        "for col in columns:\n",
        "    dfx = df[df[col]<10] \n",
        "    dfx_sec = df_sec[df_sec[col]<10] \n",
        "    print(col)\n",
        "    violin_parts = plt.violinplot(dfx[col])\n",
        "    violin_parts['bodies'][0].set_facecolor('blue')\n",
        "    violin_parts = plt.violinplot(dfx_sec[col])\n",
        "    violin_parts['bodies'][0].set_facecolor('red')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfkH8sWvjG2B",
        "outputId": "7b9f896f-a5f7-4e16-adb5-d8b0bb2a7795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reject changed_lines_count_avg   modified_lines_count_avg   0.7509015966320309\n",
            "reject changed_lines_count_avg   removed_lines_count_avg   0.8875066337290967\n",
            "reject changed_lines_count_max   removed_lines_count_max   0.7736348093894371\n",
            "reject changes_to_file_in_next_50_commits_avg   changes_to_file_in_prev_50_commits_avg   0.8161263389912828\n",
            "reject commits_next_30_days   commits_next_7_days   0.7514881424386198\n",
            "reject commits_to_next_merge   time_to_next_merge   0.8942017452229211\n",
            "reject dmm_unit_complexity   dmm_unit_size   0.8433305592596632\n",
            "reject file_token_count_avg   file_token_count_max   0.8066113020658686\n",
            "reject is_add   is_modify   -0.8502462112345345\n",
            "reject methods_with_malicious_count_avg   methods_with_malicious_count_max   0.7598245512334635\n",
            "reject total_methods_count_avg   total_methods_count_max   0.7951355002748509\n"
          ]
        }
      ],
      "source": [
        "correlation_matrix = X.corr()\n",
        "corr = correlation_matrix.values\n",
        "column_names = correlation_matrix.columns\n",
        "\n",
        "for i in range(len(column_names)):\n",
        "    for j in range(i+1, len(column_names)):\n",
        "        if abs(corr[i,j])> 0.75:\n",
        "            print('reject', column_names[i], ' ', column_names[j], ' ', corr[i,j])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyZBm-DYTg2s"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7hDFcwuBw5v4"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "\n",
        "VERBOSE_LVL = 10\n",
        "\n",
        "\n",
        "oversample_ratio = 4\n",
        "undersample_ratio = 8\n",
        "\n",
        "RF_estimators = 60\n",
        "\n",
        "\n",
        "train_SVC_linear = True\n",
        "train_SVC_sigmoid = False\n",
        "train_LR = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GbrDcL9njIlZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# manual rebalancing\n",
        "\n",
        "x_positive = X.where(y==True).dropna()\n",
        "x_negative = X.where(y==False).dropna()\n",
        "\n",
        "x_positive = pd.concat([x_positive for i in range(oversample_ratio)])\n",
        "x_negative = x_negative.sample(len(x_positive)*undersample_ratio)\n",
        "\n",
        "X_resampled = pd.concat([x_negative, x_positive])\n",
        "y_resampled = np.array([False]*len(x_negative) + [True]*len(x_positive))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8V0bMfeYjJiZ"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "\n",
        "\n",
        "# # statistical rebalancing with SMOTE AID\n",
        "# oversample_ratio = 2\n",
        "# undersample_ratio = 1\n",
        "\n",
        "# sampler = SMOTE()\n",
        "\n",
        "# x_positive = X.where(y).dropna()\n",
        "# x_negative = X.where(y==False).dropna()\n",
        "\n",
        "# x_negative_temp = x_negative.sample(len(x_positive)*oversample_ratio)\n",
        "# X_resampled_temp = pd.concat([x_negative_temp, x_positive])\n",
        "# y_resampled_temp = np.array([False]*len(x_negative_temp) + [True]*len(x_positive))\n",
        "\n",
        "# X_resampled_temp, y_resampled_temp = sampler.fit_resample(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "# x_negative_temp2 = x_negative.sample(len(X_resampled_temp)*undersample_ratio)\n",
        "# X_resampled = np.concatenate([X_resampled_temp, x_negative_temp2])\n",
        "# y_resampled = np.concatenate([y_resampled_temp, [False]*(len(X_resampled_temp)*undersample_ratio)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYFFlCLjjKhJ",
        "outputId": "0e929368-8d29-458b-83b8-c28bd351b6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28276, 110) (226208, 110) (254484, 110)\n"
          ]
        }
      ],
      "source": [
        "print(x_positive.shape, x_negative.shape, X_resampled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8Dsqn-5kjLTp"
      },
      "outputs": [],
      "source": [
        "# scaling\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler().fit(X_resampled)\n",
        "X_resampled = scaler.transform(X_resampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yEPzLYADjMLh"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug3yy1jEjNGB",
        "outputId": "9220dc8a-a7a2-4086-f227-1926f371f3aa"
      },
      "outputs": [],
      "source": [
        "# Train selector & RF\n",
        "    \n",
        "model = RandomForestClassifier(\n",
        "    n_estimators = RF_estimators,\n",
        "    random_state=42)\n",
        "\n",
        "selector = RFECV(model, \n",
        "    step=1, \n",
        "    cv=5,\n",
        "    min_features_to_select=40,\n",
        "    n_jobs = 20,\n",
        "    scoring = 'f1',\n",
        "    \n",
        "    verbose=VERBOSE_LVL)\n",
        "\n",
        "selector.fit(X_resampled, y_resampled)\n",
        "\n",
        "print('max f1:', max(selector.cv_results_['mean_test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0udPBgwjOJR"
      },
      "outputs": [],
      "source": [
        "#dict_keys(['mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
        "# print(selector.cv_results_['mean_test_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8kBmNadjPCh"
      },
      "outputs": [],
      "source": [
        "if VERBOSE_LVL > 5:\n",
        "  colums = list(X.columns)\n",
        "\n",
        "  print('Selected features')\n",
        "  for i in range(len(selector.support_)):\n",
        "      if selector.support_[i]:\n",
        "          print(colums[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54A0HXW8jQmZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df_eval_selected = eval_df\n",
        "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(broken_features)]\n",
        "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(no_variance_features)]\n",
        "df_eval_selected = df_eval_selected[df_eval_selected.columns.difference(highly_correlated_features)]\n",
        "\n",
        "eval_X = df_eval_selected[df_eval_selected.columns.difference(['label_repo_full_name', 'label_sha', 'label_commit_date', 'label_security_related'])]\n",
        "eval_y = df_eval_selected['label_security_related']\n",
        "\n",
        "\n",
        "eval_x_positive = eval_X.where(eval_y).dropna()\n",
        "eval_x_negative = eval_X.where(eval_y==False).dropna()\n",
        "print(eval_x_positive.shape, eval_x_negative.shape)\n",
        "\n",
        "eval_x_negative_sampled =  eval_x_negative.sample(len(eval_x_positive)*undersample_ratio)\n",
        "\n",
        "eval_X_balanced = pd.concat([eval_x_negative_sampled, eval_x_positive])\n",
        "eval_y_balanced = np.array([False]*len(eval_x_negative_sampled) + [True]*len(eval_x_positive))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRViXWhCH5so"
      },
      "outputs": [],
      "source": [
        "eval_y = eval_y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXGvgnWmjRcp"
      },
      "outputs": [],
      "source": [
        "# eval RF selector\n",
        "\n",
        "eval_scaled = scaler.transform(eval_X)\n",
        "eval_selected_scaled = selector.transform(eval_scaled)\n",
        "X_resampled_selected = selector.transform(X_resampled)\n",
        "eval_X_balanced_selected = selector.transform(eval_X_balanced)\n",
        "\n",
        "train_preds = selector.predict(X_resampled)\n",
        "recall = recall_score(y_resampled, train_preds)\n",
        "precision = precision_score(y_resampled, train_preds)\n",
        "print('RF train', recall, precision)\n",
        "\n",
        "eval_balanced_y_pred = selector.predict(eval_X_balanced)\n",
        "recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "print('RF test', recall, precision)\n",
        "\n",
        "eval_y_pred = selector.predict(eval_scaled)\n",
        "precision_rf = precision_score(eval_y, eval_y_pred)\n",
        "recall_rf = recall_score(eval_y, eval_y_pred)\n",
        "f1_rf = 2*recall_rf*precision_rf/(recall_rf+precision_rf)\n",
        "\n",
        "print('RF eval', recall_rf, precision_rf, f1_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm0L6Fc4jSih"
      },
      "outputs": [],
      "source": [
        "if train_SVC_linear:\n",
        "  SVC_model = LinearSVC(\n",
        "      penalty ='l2',\n",
        "      loss='squared_hinge',\n",
        "      random_state=42,\n",
        "      verbose=VERBOSE_LVL)\n",
        "\n",
        "  SVC_model.fit(X_resampled_selected, y_resampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtIAa6sijTRx"
      },
      "outputs": [],
      "source": [
        "if train_SVC_linear:\n",
        "  train_preds = SVC_model.predict(X_resampled_selected)\n",
        "  recall = recall_score(y_resampled, train_preds)\n",
        "  precision = precision_score(y_resampled, train_preds)\n",
        "  print('SVC train', recall, precision)\n",
        "\n",
        "  eval_balanced_y_pred = SVC_model.predict(eval_X_balanced_selected)\n",
        "  recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "  precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "  print('SVC test', recall, precision)\n",
        "\n",
        "  eval_y_pred = SVC_model.predict(eval_selected_scaled)\n",
        "  recall_svc = recall_score(eval_y, eval_y_pred)\n",
        "  precision_svc = precision_score(eval_y, eval_y_pred)\n",
        "  f1_svc = 2*recall_svc*precision_svc/(recall_svc+precision_svc)\n",
        "\n",
        "  print('SVC eval', recall_svc, precision_svc, f1_svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuwl5sxCjUNR"
      },
      "outputs": [],
      "source": [
        "if train_SVC_sigmoid:\n",
        "  SVC_model_2 = SVC(\n",
        "      kernel ='sigmoid',\n",
        "      random_state=42,\n",
        "      verbose=VERBOSE_LVL>0)\n",
        "\n",
        "  SVC_model_2.fit(X_resampled_selected, y_resampled)\n",
        "\n",
        "  train_preds = SVC_model_2.predict(X_resampled_selected)\n",
        "  recall = recall_score(y_resampled, train_preds)\n",
        "  precision = precision_score(y_resampled, train_preds)\n",
        "  print('SVC2 train', recall, precision)\n",
        "\n",
        "  eval_balanced_y_pred = SVC_model_2.predict(eval_X_balanced_selected)\n",
        "  recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "  precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "  print('SVC2 test', recall, precision)\n",
        "\n",
        "  eval_y_pred = SVC_model_2.predict(eval_selected_scaled)\n",
        "  recall_svc2 = recall_score(eval_y, eval_y_pred)\n",
        "  precision_svc2 = precision_score(eval_y, eval_y_pred)\n",
        "  f1_svc2 = 2*recall_svc2*precision_svc2/(precision_svc2+recall_svc2)\n",
        "\n",
        "  print('SVC2 eval', recall_svc2, precision_svc2, f1_svc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c91bLvqjU_p"
      },
      "outputs": [],
      "source": [
        "if train_LR:\n",
        "  LR_model = LogisticRegression(\n",
        "      penalty ='l2',\n",
        "      max_iter = 20000,\n",
        "      random_state=42)\n",
        "\n",
        "  LR_model.fit(X_resampled_selected, y_resampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgGKJiJmjV8x"
      },
      "outputs": [],
      "source": [
        "if train_LR:\n",
        "  train_preds = LR_model.predict(X_resampled_selected)\n",
        "  recall = recall_score(y_resampled, train_preds)\n",
        "  precision = precision_score(y_resampled, train_preds)\n",
        "  print('LR train', recall, precision)\n",
        "\n",
        "  eval_balanced_y_pred = LR_model.predict(eval_X_balanced_selected)\n",
        "  recall = recall_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "  precision = precision_score(eval_y_balanced, eval_balanced_y_pred)\n",
        "  print('LR test', recall, precision)\n",
        "\n",
        "  eval_y_pred = LR_model.predict(eval_selected_scaled)\n",
        "  recall_lr = recall_score(eval_y, eval_y_pred)\n",
        "  precision_lr = precision_score(eval_y, eval_y_pred)\n",
        "  f1_lr = 2*recall_lr*precision_lr/(precision_lr+recall_lr)\n",
        "\n",
        "  print('LR eval', recall_lr, precision_lr, f1_lr)\n",
        "\n",
        "  # eval_y_pred = LR_model.predict(eval_selected_scaled)\n",
        "  # recall = recall_score(eval_y, eval_y_pred)\n",
        "  # precision = precision_score(eval_y, eval_y_pred)\n",
        "  # print('LR', recall, precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0GWQc1WjXh5"
      },
      "outputs": [],
      "source": [
        "# eval_y_pred4 = LR_model.predict(eval_selected_scaled)\n",
        "# eval_y_pred = [False]*len(eval_y_pred4)\n",
        "\n",
        "# for x in range(len(eval_y_pred4)):\n",
        "#     if eval_y_pred4[x]:\n",
        "#         eval_y_pred[x]=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scha_SEwjYdB"
      },
      "outputs": [],
      "source": [
        "# x_true = [False]*len(eval_y)\n",
        "# eval_y2 = eval_y.reset_index()\n",
        "# for x in range(len(eval_y2)):\n",
        "#     if eval_y_pred4[x] and eval_y2.iloc[x]['label_security_related']:\n",
        "#         x_true[x]=True\n",
        "    \n",
        "# true_positives = sum(1  for x in x_true if x)\n",
        "# al_positives = (eval_df['label_security_related']==True).sum()\n",
        "# print(true_positives/al_positives) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7E76XeIjZUJ"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# ix = 0\n",
        "# shas = []\n",
        "# for i, x in eval_df.iterrows():\n",
        "#     shas.append({\n",
        "#         'label_sha':x['label_sha'],\n",
        "#         'label_repo_full_name':x['label_repo_full_name'],\n",
        "#         'classification_pred': eval_y_pred[ix]\n",
        "#     })\n",
        "\n",
        "#     ix += 1\n",
        "\n",
        "# with open('classificated_commits.json', 'w') as f:\n",
        "#     json.dump(shas, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo9ylj49TqCE"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6IKjW9sjalh"
      },
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "\n",
        "dump(selector, 'RF_selector.joblib') \n",
        "if train_LR:\n",
        "  dump(LR_model, 'LR_model_all.joblib') \n",
        "if train_SVC_linear:\n",
        "  dump(SVC_model, 'SVC_linear_model_all.joblib') \n",
        "if train_SVC_sigmoid:\n",
        "  dump(SVC_model_2, 'SVC_sigmoid_model_all.joblib') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsqsIToiS1R_"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('RF eval', recall_rf, precision_rf, f1_rf)\n",
        "print('LR eval', recall_lr, precision_lr, f1_lr)\n",
        "print('SVC eval', recall_svc, precision_svc, f1_svc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
