{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# import sys\n",
    "# sys.path.insert(0, r'PATH_TO_REPO')\n",
    "\n",
    "import gc\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "from src.dl.datasets.CommitLevelRawDataset import CommitLevelRawDataset\n",
    "from src.dl.datasets.SampleLevelRawDataset import SampleLevelRawDataset\n",
    "from src.dl.datasets.supporting.CsvDataset import CsvDataset\n",
    "from src.dl.datasets.sampling.OverSampledDataset import OverSampledDataset\n",
    "from src.dl.datasets.sampling.UnderSampledDataset import UnderSampledDataset\n",
    "\n",
    "from src.dl.dl_utils import save_dataset, read_dataset, get_repo_seminames, get_files_in_set\n",
    "from src.utils.utils import get_files_in_from_directory\n",
    "from src.dl.models.BertAndLinear import BertAndLinear as FineTuningModel\n",
    "from src.dl.models.LstmAggregator import LstmAggregator as AggregatorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "base_model = 'microsoft/graphcodebert-base'\n",
    "batch_size_ = 4\n",
    "num_epochs_ = 3\n",
    "\n",
    "fraction_of_data = 1\n",
    "\n",
    "sample_limit = 5_000\n",
    "eval_sample_limit = 2_000\n",
    "test_percentage = 0.15\n",
    "eval_percentage = 0.05\n",
    "\n",
    "learning_rate = 1e-6\n",
    "oversampling_ratio = 2\n",
    "class_ratio = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator_num_epochs_ = 15\n",
    "aggregator_class_ratio = 2\n",
    "aggregator_learning_rate = 5e-6\n",
    "\n",
    "save_model_in_each_epoch = True\n",
    "eval_model_in_each_epoch = True\n",
    "\n",
    "model_guid = str(uuid.uuid4())\n",
    "model_name = model_guid\n",
    "\n",
    "work_dir = f'D:\\\\Projects\\\\aaa\\src\\\\rq5\\\\binaries\\\\{model_name}'\n",
    "results_dir = f'D:\\\\Projects\\\\aaa\\src\\\\rq5\\\\binaries\\\\data{model_name}'\n",
    "\n",
    "# Data config - Set to None if you want to use cached datasets\n",
    "raw_input_path = 'D:\\\\Projects\\\\aaa\\\\results\\\\dl\\\\java2\\\\CodeParserMiner_ast'\n",
    "# raw_input_path = 'D:\\\\Projects\\\\aaa\\\\results\\\\dl\\\\java2\\\\CodeParserMiner_edit'\n",
    "# raw_input_path = 'D:\\\\Projects\\\\aaa\\\\results\\\\dl\\\\java2\\\\AddedCodeMiner'\n",
    "# raw_input_path = 'D:\\\\Projects\\\\aaa\\\\results\\\\dl\\\\java2\\\\RollingWindowMiner'\n",
    "# raw_input_path = None\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(work_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(results_dir) \n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, scheduler, eval_loader = None):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    accumulated_loss = 0\n",
    "    all_samples = 0\n",
    "    positive_samples = 0\n",
    "\n",
    "    for epoch in range(num_epochs_):\n",
    "        print(f'Epoch {epoch}/{num_epochs_}')\n",
    "        accumulated_loss = 0\n",
    "\n",
    "        with tqdm.tqdm(total=len(data_loader)) as pbar:\n",
    "            for data_inputs, data_labels in data_loader:\n",
    "                # Step 0: Diagnostics :x\n",
    "                positive_samples += len([1 for x in data_labels if x[0] == 1])\n",
    "                all_samples += len(data_labels)\n",
    "                \n",
    "                # Step 1: Mode data to device\n",
    "                data_inputs = data_inputs.to(device)\n",
    "                data_labels = data_labels.to(device)\n",
    "\n",
    "                # Step 2: Calculate model output\n",
    "                preds = model(data_inputs)\n",
    "                preds = preds.squeeze(dim=0)\n",
    "\n",
    "                # Step 3: Calculate loss\n",
    "                loss = loss_module(preds, data_labels.float())\n",
    "                accumulated_loss += loss.item()\n",
    "\n",
    "                ## Step 4: Perform backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                ## Step 5: Update the parameters\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                # Step 6: Progress bar\n",
    "                pbar.update()\n",
    "        print('Loss in this epoch:', accumulated_loss)\n",
    "\n",
    "        if save_model_in_each_epoch:\n",
    "            torch.save(model.state_dict(), f'{work_dir}/model_{model_name}_epoch_{epoch}.pickle')\n",
    "\n",
    "        if eval_loader != None:\n",
    "            eval_model(model, eval_loader)\n",
    "\n",
    "\n",
    "    print(f'Model saw positive samples {positive_samples} times and background samples {all_samples-positive_samples}')\n",
    "    print(f'Ratio 1:{(all_samples-positive_samples)/positive_samples}')\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    data_size = len(data_loader)\n",
    "    with tqdm.tqdm(total=data_size) as pbar:\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=0)\n",
    "\n",
    "            labels_in_memory = data_labels.cpu().detach().numpy()\n",
    "            if len(labels_in_memory.shape) == 1:\n",
    "                all_labels.append(labels_in_memory)\n",
    "            else:\n",
    "                for x in labels_in_memory:\n",
    "                    all_labels.append(x)\n",
    "                    \n",
    "            preds_in_memory = preds.cpu().detach().numpy()\n",
    "            if labels_in_memory.shape[0] == 1:\n",
    "                all_predictions.append(preds_in_memory)\n",
    "            else:\n",
    "                for x in preds_in_memory:\n",
    "                    all_predictions.append(x)\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "    predictions_arr = [1 if x[0]>x[1] else 0 for x in all_predictions] #TODO softmax\n",
    "    targets_arr = [1 if x[0]>x[1] else 0 for x in all_labels]\n",
    "    P = len([1 for x in range(len(predictions_arr)) if predictions_arr[x]==1])\n",
    "    TP = len([1 for x in range(len(predictions_arr)) if predictions_arr[x]==1 and targets_arr[x]==1])\n",
    "    FP = len([1 for x in range(len(predictions_arr)) if predictions_arr[x]==1 and targets_arr[x]==0])\n",
    "    FN = len([1 for x in range(len(predictions_arr)) if predictions_arr[x]==0 and targets_arr[x]==1])\n",
    "    TN = len([1 for x in range(len(predictions_arr)) if predictions_arr[x]==0 and targets_arr[x]==0])\n",
    "    N = len([1 for x in range(len(predictions_arr)) if predictions_arr[x]==0])\n",
    "\n",
    "    precission = TP/(TP+FP) if (TP+FP)!=0 else 0\n",
    "    recall = TP/(TP+FN) if (TP+FN)!=0 else 0\n",
    "    print('Precission:',f'{TP}/{TP+FP}', precission)\n",
    "    print('Recall', f'{TP}/{TP+FN}', recall)\n",
    "    print(f'P:{P},', f'TP:{TP},', f'FP:{FP},', f'FN:{FN},', f'TN:{TN},', f'N:{N}')\n",
    "\n",
    "    return precission, recall\n",
    "\n",
    "\n",
    "def load_files(input_path, data_fraction=1):\n",
    "    positive_json_files = get_files_in_from_directory(input_path, extension='.json', startswith='positive-encodings')\n",
    "    background_json_files = get_files_in_from_directory(input_path, extension='.json', startswith='background-encodings')\n",
    "\n",
    "    if data_fraction < 1:\n",
    "        positive_json_files = random.sample(positive_json_files, int(len(positive_json_files)*data_fraction))\n",
    "        background_json_files = random.sample(background_json_files, int(len(background_json_files)*data_fraction))\n",
    "\n",
    "\n",
    "    repos_set = get_repo_seminames(positive_json_files)\n",
    "    repos_count = len(repos_set)\n",
    "\n",
    "\n",
    "    repos_test = set(random.sample(list(repos_set), int(repos_count*test_percentage)))\n",
    "    repos_set.difference_update(repos_test)\n",
    "    repos_eval = set(random.sample(list(repos_set), int(repos_count*test_percentage)))\n",
    "    repos_set.difference_update(repos_eval)\n",
    "\n",
    "    positive_train = get_files_in_set(positive_json_files, repos_set)\n",
    "    positive_eval = get_files_in_set(positive_json_files, repos_eval)\n",
    "    positive_test = get_files_in_set(positive_json_files, repos_test)\n",
    "\n",
    "    background_train = get_files_in_set(background_json_files, repos_set)\n",
    "    background_eval = get_files_in_set(background_json_files, repos_eval)\n",
    "    background_test = get_files_in_set(background_json_files, repos_test)\n",
    "\n",
    "    return (positive_json_files, background_json_files), (positive_train, background_train), (positive_eval, background_eval), (positive_test, background_test)\n",
    "\n",
    "\n",
    "def load_data(input_data, oversampling_ratio=None, class_ratio=None, sample_limit=None):\n",
    "    positive_files = input_data[0]\n",
    "    background_files = input_data[1]\n",
    "\n",
    "    dataset = SampleLevelRawDataset()\n",
    "    dataset.load_files(positive_files, background_files)\n",
    "\n",
    "    if oversampling_ratio != None and class_ratio != None and sample_limit != None:\n",
    "        dataset.setup_ratios(oversampling_ratio, class_ratio, sample_limit)   \n",
    "\n",
    "    if oversampling_ratio == None and class_ratio == None and sample_limit != None:\n",
    "        dataset.limit_data(sample_limit)   \n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_file_datasets(file_dataset, dataset_type):\n",
    "    data = {\n",
    "        'positive_files': file_dataset[0],\n",
    "        'background_files': file_dataset[1]\n",
    "    }\n",
    "    with open(os.path.join(results_dir, f'{dataset_type}-files.json'), 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def load_file_dataset(dataset_type):\n",
    "    with open(os.path.join(results_dir, f'{dataset_type}-files.json'), 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return (data['positive_files'], data['background_files'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, train_data, eval_data, test_data = load_files(raw_input_path, fraction_of_data)\n",
    "save_file_datasets(train_data, 'train_data')\n",
    "save_file_datasets(eval_data, 'eval_data')\n",
    "save_file_datasets(test_data, 'test_data')\n",
    "\n",
    "train_data = load_file_dataset('train_data')\n",
    "eval_data = load_file_dataset('eval_data')\n",
    "test_data = load_file_dataset('test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_and_eval():\n",
    "    train_dataset = load_data(train_data, oversampling_ratio, class_ratio, sample_limit)\n",
    "    eval_dataset = load_data(eval_data, sample_limit=eval_sample_limit)\n",
    "    test_dataset = load_data(test_data)\n",
    "\n",
    "    # Define model\n",
    "    model = FineTuningModel(base_model)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "        num_warmup_steps=int(len(train_dataset)*0.25), \n",
    "        num_training_steps=len(train_dataset)*num_epochs_)\n",
    "\n",
    "    # Prep the loaders\n",
    "    train_data_loader = data.DataLoader(train_dataset, batch_size=batch_size_, drop_last=True, shuffle=True)\n",
    "    eval_data_loader = data.DataLoader(eval_dataset, batch_size=batch_size_, drop_last=True, shuffle=True)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, optimizer, train_data_loader, loss_module, scheduler, eval_loader=eval_data_loader)\n",
    "    torch.save(model.state_dict(), f'{work_dir}/model_{model_name}_final.pickle')\n",
    "\n",
    "    # Test the model on test subset\n",
    "    test_data_loader = data.DataLoader(test_dataset, drop_last=True, batch_size=batch_size_)\n",
    "    precision, recall = eval_model(model, test_data_loader)\n",
    "    return model, precision, recall\n",
    "\n",
    "# model, precision, recall = finetune_and_eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "learning_rates = [2e-6, 2e-5]\n",
    "oversampling_ratios = [1,2,4,-1]\n",
    "class_ratios = [1,2,4,8]\n",
    "for lrx in learning_rates:\n",
    "    for orx in oversampling_ratios:\n",
    "        for crx in class_ratios:\n",
    "            learning_rate = lrx\n",
    "            oversampling_ratio = orx\n",
    "            class_ratio = crx\n",
    "            model, precision, recall = finetune_and_eval()\n",
    "            del model\n",
    "\n",
    "            print()\n",
    "            print('XXX')\n",
    "            print('learning_rate', learning_rate)\n",
    "            print('oversampling_ratio', oversampling_ratio)\n",
    "            print('class_ratio', class_ratio)\n",
    "            print('precision', precision)\n",
    "            print('recall', recall)\n",
    "            print('XXX')\n",
    "            print()\n",
    "            data.append({\n",
    "                'learning_rate': learning_rate,\n",
    "                'oversampling_ratio': oversampling_ratio,\n",
    "                'class_ratio': class_ratio,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "            })\n",
    "\n",
    "            torch.cuda.empty_cache() \n",
    "            gc.collect()\n",
    "\n",
    "with open('results-summary-1.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
